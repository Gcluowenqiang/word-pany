use crate::models::{Word, Example, WordFilter};
use anyhow::{Result, anyhow};
use quick_xml::events::Event;
use quick_xml::reader::Reader;
use quick_xml::writer::Writer;
use std::collections::HashMap;
use std::fs;
use std::io::Cursor;
use std::path::{Path, PathBuf};
use chrono::Utc;
use uuid::Uuid;
use regex::Regex;

static mut WORDS_CACHE: Option<Vec<Word>> = None;
static CACHE_LOCK: std::sync::Mutex<()> = std::sync::Mutex::new(());

pub async fn clear_cache() {
    let _lock = CACHE_LOCK.lock().unwrap();
    unsafe { WORDS_CACHE = None; }
    println!("ğŸ§¹ å•è¯ç¼“å­˜å·²æ¸…ç†");
}

pub async fn load_words(filter: Option<WordFilter>) -> Result<Vec<Word>> {
    let words = {
        let _lock = CACHE_LOCK.lock().unwrap();
        
        // å¦‚æœç¼“å­˜ä¸ºç©ºï¼Œåˆ™ä»æ–‡ä»¶åŠ è½½
        if unsafe { WORDS_CACHE.is_none() } {
            println!("ğŸ“š ç¼“å­˜ä¸ºç©ºï¼Œä»æ–‡ä»¶é‡æ–°åŠ è½½å•è¯æ•°æ®...");
            drop(_lock); // é‡Šæ”¾é”ä»¥ä¾¿åœ¨å¼‚æ­¥è°ƒç”¨æœŸé—´é¿å…Sendé—®é¢˜
            let words = load_words_from_file().await?;
            let _lock = CACHE_LOCK.lock().unwrap();
            unsafe { WORDS_CACHE = Some(words); }
            println!("âœ… å•è¯æ•°æ®å·²åŠ è½½åˆ°ç¼“å­˜ï¼Œå…± {} ä¸ªå•è¯", unsafe { WORDS_CACHE.as_ref().unwrap().len() });
        } else {
            println!("ğŸ’¾ ä½¿ç”¨å·²ç¼“å­˜çš„å•è¯æ•°æ®ï¼Œå…± {} ä¸ªå•è¯", unsafe { WORDS_CACHE.as_ref().unwrap().len() });
        }
        
        unsafe { WORDS_CACHE.as_ref().unwrap().clone() }
    };
    
    // åº”ç”¨è¿‡æ»¤å™¨
    let filtered_words = if let Some(filter) = filter {
        apply_filter(&words, &filter)
    } else {
        words
    };
    
    println!("ğŸ” è¿”å›ç»™å‰ç«¯çš„å•è¯æ•°é‡: {}", filtered_words.len());
    if !filtered_words.is_empty() {
        println!("ğŸ“– ç¬¬ä¸€ä¸ªå•è¯ç¤ºä¾‹: {} - {}", filtered_words[0].word, filtered_words[0].trans);
    }
    
    Ok(filtered_words)
}

pub async fn get_word_by_id(id: &str) -> Result<Option<Word>> {
    let words = load_words(None).await?;
    Ok(words.into_iter().find(|w| w.id == id))
}

pub async fn update_word_progress(id: &str, progress: u8, is_correct: bool) -> Result<()> {
    let words_to_save = {
        let _lock = CACHE_LOCK.lock().unwrap();
        
        if let Some(words) = unsafe { WORDS_CACHE.as_mut() } {
            if let Some(word) = words.iter_mut().find(|w| w.id == id) {
                word.update_progress(progress, is_correct);
                Some(words.clone())
            } else {
                None
            }
        } else {
            None
        }
    };
    
    if let Some(words) = words_to_save {
        save_words_to_file(&words).await?;
        
        // æ›´æ–°ç¼“å­˜
        let _lock = CACHE_LOCK.lock().unwrap();
        unsafe { WORDS_CACHE = Some(words); }
    }
    
    Ok(())
}

pub async fn search_words(query: &str, limit: u32) -> Result<Vec<Word>> {
    let words = load_words(None).await?;
    let query_lower = query.to_lowercase();
    
    let mut results: Vec<Word> = words
        .into_iter()
        .filter(|word| {
            word.word.to_lowercase().contains(&query_lower) ||
            word.trans.to_lowercase().contains(&query_lower) ||
            word.examples.iter().any(|ex| 
                ex.source.to_lowercase().contains(&query_lower) ||
                ex.trans.to_lowercase().contains(&query_lower)
            )
        })
        .take(limit as usize)
        .collect();
    
    // æŒ‰ç›¸å…³æ€§æ’åºï¼ˆç²¾ç¡®åŒ¹é…ä¼˜å…ˆï¼‰
    results.sort_by(|a, b| {
        let a_exact = a.word.to_lowercase() == query_lower;
        let b_exact = b.word.to_lowercase() == query_lower;
        
        match (a_exact, b_exact) {
            (true, false) => std::cmp::Ordering::Less,
            (false, true) => std::cmp::Ordering::Greater,
            _ => a.word.cmp(&b.word),
        }
    });
    
    Ok(results)
}

async fn load_words_from_file() -> Result<Vec<Word>> {
    println!("ğŸ“ å¼€å§‹åŠ è½½è¯æ±‡æ–‡ä»¶...");
    
    // ä¼˜å…ˆä½¿ç”¨Taurièµ„æºæ–‡ä»¶ï¼ˆé€‚ç”¨äºæ‰“åŒ…åçš„åº”ç”¨ï¼‰
    if let Ok(content) = load_from_tauri_resource().await {
        println!("âœ… ä»Taurièµ„æºæ–‡ä»¶åŠ è½½æˆåŠŸ");
        return parse_xml_content(&content).await;
    }
    
    // å¦‚æœèµ„æºæ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œå°è¯•å…¶ä»–è·¯å¾„ï¼ˆå¼€å‘ç¯å¢ƒæˆ–å¤‡ä»½æ–¹æ¡ˆï¼‰
    println!("âš ï¸ Taurièµ„æºæ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œå°è¯•å…¶ä»–è·¯å¾„...");
    
    // å°è¯•ä»åº”ç”¨ç¨‹åºç›®å½•è¯»å–
    if let Ok(app_dir) = get_app_directory() {
        let app_vocab_path = app_dir.join("software_vocabulary.xml");
        if app_vocab_path.exists() {
            println!("ğŸ“ ä»åº”ç”¨ç¨‹åºç›®å½•åŠ è½½: {:?}", app_vocab_path);
            let content = fs::read_to_string(&app_vocab_path)
                .map_err(|e| anyhow!("æ— æ³•è¯»å–åº”ç”¨ç¨‹åºç›®å½•è¯æ±‡æ–‡ä»¶: {}", e))?;
            return parse_xml_content(&content).await;
        }
    }
    
    // å°è¯•ä»é¡¹ç›®æ ¹ç›®å½•è¯»å–ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    let current_dir = std::env::current_dir()?;
    let project_vocab_path = current_dir.join("software_vocabulary.xml");
    
    if project_vocab_path.exists() {
        println!("ğŸ“ ä»é¡¹ç›®æ ¹ç›®å½•åŠ è½½: {:?}", project_vocab_path);
        let content = fs::read_to_string(&project_vocab_path)
            .map_err(|e| anyhow!("æ— æ³•è¯»å–é¡¹ç›®è¯æ±‡æ–‡ä»¶: {}", e))?;
        return parse_xml_content(&content).await;
    }
    
    // æœ€åå°è¯•ä»æ•°æ®ç›®å½•è¯»å–æˆ–åˆ›å»º
    println!("ğŸ“ å°è¯•ä»ç”¨æˆ·æ•°æ®ç›®å½•åŠ è½½æˆ–åˆ›å»ºæ–‡ä»¶...");
    let data_dir = get_data_directory()?;
    let data_vocab_path = data_dir.join("vocabulary").join("software_vocabulary.xml");
    
    if !data_vocab_path.exists() {
        create_default_vocabulary_file(&data_vocab_path).await?;
    }
    
    let content = fs::read_to_string(&data_vocab_path)
        .map_err(|e| anyhow!("æ— æ³•è¯»å–æ•°æ®ç›®å½•è¯æ±‡æ–‡ä»¶: {}", e))?;
    
    parse_xml_content(&content).await
}

async fn save_words_to_file(words: &[Word]) -> Result<()> {
    let data_dir = get_data_directory()?;
    let vocab_path = data_dir.join("vocabulary").join("software_vocabulary.xml");
    
    // ç¡®ä¿ç›®å½•å­˜åœ¨
    if let Some(parent) = vocab_path.parent() {
        fs::create_dir_all(parent)?;
    }
    
    let xml_content = generate_xml_content(words)?;
    fs::write(&vocab_path, xml_content)
        .map_err(|e| anyhow!("æ— æ³•ä¿å­˜è¯æ±‡æ–‡ä»¶: {}", e))?;
    
    Ok(())
}

async fn parse_xml_content(content: &str) -> Result<Vec<Word>> {
    println!("ğŸ“„ å¼€å§‹è§£æXMLå†…å®¹ï¼Œæ–‡ä»¶å¤§å°: {} å­—èŠ‚", content.len());
    
    let mut reader = Reader::from_str(content);
    reader.trim_text(true);
    
    let mut words = Vec::new();
    let mut current_word: Option<Word> = None;
    let mut current_example: Option<Example> = None;
    let mut buf = Vec::new();
    let mut current_element = String::new();
    let mut text_content = String::new();
    
    loop {
        match reader.read_event_into(&mut buf) {
            Err(e) => return Err(anyhow!("XMLè§£æé”™è¯¯: {}", e)),
            Ok(Event::Eof) => break,
            
            Ok(Event::Start(ref e)) => {
                current_element = String::from_utf8_lossy(e.name().as_ref()).to_string();
                text_content.clear();
                
                match current_element.as_str() {
                    "item" => current_word = Some(Word::default()),
                    "example" => current_example = Some(Example {
                        source: String::new(),
                        trans: String::new(),
                    }),
                    _ => {}
                }
            }
            
            Ok(Event::Text(e)) => {
                let raw_text = e.unescape()?.into_owned();
                // å¤„ç†åŒé‡ç¼–ç çš„æ–‡æœ¬å†…å®¹
                let decoded_text = raw_text
                    .replace("&amp;lt;", "<")
                    .replace("&amp;gt;", ">")
                    .replace("&amp;quot;", "\"")
                    .replace("&amp;apos;", "'")
                    .replace("&amp;amp;", "&");
                text_content.push_str(&decoded_text);
            }
            
            Ok(Event::CData(e)) => {
                text_content.push_str(&String::from_utf8_lossy(&e.into_inner()));
            }
            
            Ok(Event::End(ref e)) => {
                let element_name = String::from_utf8_lossy(e.name().as_ref()).to_string();
                
                match element_name.as_str() {
                    "word" => {
                        if let Some(ref mut word) = current_word {
                            word.word = text_content.trim().to_string();
                        }
                    }
                    "trans" => {
                        if let Some(ref mut example) = current_example {
                            example.trans = clean_html_tags(&text_content);
                        } else if let Some(ref mut word) = current_word {
                            word.trans = clean_html_tags(&text_content);
                        }
                    }
                    "phonetic" => {
                        if let Some(ref mut word) = current_word {
                            word.phonetic = clean_html_tags(&text_content);
                        }
                    }
                    "tags" => {
                        if let Some(ref mut word) = current_word {
                            word.tags = vec![text_content.trim().to_string()];
                        }
                    }
                    "progress" => {
                        if let Some(ref mut word) = current_word {
                            word.progress = text_content.trim().parse().unwrap_or(1);
                        }
                    }
                    "note" => {
                        if let Some(ref mut word) = current_word {
                            word.note = clean_html_tags(&text_content);
                        }
                    }
                    "source" => {
                        if let Some(ref mut example) = current_example {
                            example.source = text_content.trim().to_string();
                        }
                    }
                    "example" => {
                        if let (Some(ref mut word), Some(example)) = (&mut current_word, current_example.take()) {
                            word.examples.push(example);
                        }
                    }
                    "item" => {
                        if let Some(mut word) = current_word.take() {
                            // å¦‚æœæ²¡æœ‰IDï¼Œç”Ÿæˆä¸€ä¸ª
                            if word.id.is_empty() {
                                word.id = Uuid::new_v4().to_string();
                            }
                            
                            // è®¾ç½®åˆ›å»ºæ—¶é—´
                            if word.created_at == word.updated_at {
                                word.created_at = Utc::now();
                                word.updated_at = Utc::now();
                            }
                            
                            println!("âœ… è§£æå•è¯: {} - {}", word.word, word.trans);
                            words.push(word);
                        }
                    }
                    _ => {}
                }
                
                text_content.clear();
            }
            
            _ => {}
        }
        
        buf.clear();
    }
    
    println!("ğŸ‰ XMLè§£æå®Œæˆï¼Œå…±è§£æåˆ° {} ä¸ªå•è¯", words.len());
    Ok(words)
}

fn generate_xml_content(words: &[Word]) -> Result<String> {
    let mut output = Vec::new();
    let mut writer = Writer::new(Cursor::new(&mut output));
    
    // XMLå£°æ˜
    output.extend_from_slice(b"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<wordbook>\n");
    
    for word in words {
        output.extend_from_slice(b"    <item>\n");
        
        output.extend_from_slice(format!("        <word>{}</word>\n", escape_xml(&word.word)).as_bytes());
        output.extend_from_slice(format!("        <trans><![CDATA[{}]]></trans>\n", word.trans).as_bytes());
        output.extend_from_slice(format!("        <phonetic><![CDATA[{}]]></phonetic>\n", word.phonetic).as_bytes());
        
        if !word.tags.is_empty() {
            output.extend_from_slice(format!("        <tags>{}</tags>\n", escape_xml(&word.tags[0])).as_bytes());
        }
        
        output.extend_from_slice(format!("        <progress>{}</progress>\n", word.progress).as_bytes());
        
        if !word.note.is_empty() {
            output.extend_from_slice(format!("        <note><![CDATA[{}]]></note>\n", word.note).as_bytes());
        }
        
        if !word.examples.is_empty() {
            output.extend_from_slice(b"        <examples>\n");
            for example in &word.examples {
                output.extend_from_slice(b"            <example>\n");
                output.extend_from_slice(format!("                <source>{}</source>\n", escape_xml(&example.source)).as_bytes());
                output.extend_from_slice(format!("                <trans><![CDATA[{}]]></trans>\n", example.trans).as_bytes());
                output.extend_from_slice(b"            </example>\n");
            }
            output.extend_from_slice(b"        </examples>\n");
        }
        
        output.extend_from_slice(b"    </item>\n");
    }
    
    output.extend_from_slice(b"</wordbook>\n");
    
    Ok(String::from_utf8(output)?)
}

fn apply_filter(words: &[Word], filter: &WordFilter) -> Vec<Word> {
    words
        .iter()
        .filter(|word| {
            // æ ‡ç­¾è¿‡æ»¤
            if let Some(ref tags) = filter.tags {
                if !tags.iter().any(|tag| word.tags.contains(tag)) {
                    return false;
                }
            }
            
            // éš¾åº¦è¿‡æ»¤
            if let Some(min_difficulty) = filter.difficulty_min {
                if word.difficulty < min_difficulty {
                    return false;
                }
            }
            
            if let Some(max_difficulty) = filter.difficulty_max {
                if word.difficulty > max_difficulty {
                    return false;
                }
            }
            
            // æŒæ¡ç¨‹åº¦è¿‡æ»¤
            if let Some(min_mastery) = filter.mastery_min {
                if word.mastery_level < min_mastery {
                    return false;
                }
            }
            
            if let Some(max_mastery) = filter.mastery_max {
                if word.mastery_level > max_mastery {
                    return false;
                }
            }
            
            // è¿›åº¦è¿‡æ»¤
            if let Some(min_progress) = filter.progress_min {
                if word.progress < min_progress {
                    return false;
                }
            }
            
            if let Some(max_progress) = filter.progress_max {
                if word.progress > max_progress {
                    return false;
                }
            }
            
            // æ–‡æœ¬æœç´¢
            if let Some(ref search_text) = filter.search_text {
                let search_lower = search_text.to_lowercase();
                if !word.word.to_lowercase().contains(&search_lower) &&
                   !word.trans.to_lowercase().contains(&search_lower) {
                    return false;
                }
            }
            
            true
        })
        .cloned()
        .collect()
}

fn clean_html_tags(text: &str) -> String {
    // å¤šå±‚æ¬¡HTMLå®ä½“è§£ç å¤„ç†
    let mut decoded = text.to_string();
    
    // ç¬¬ä¸€è½®ï¼šè§£ç åŒé‡ç¼–ç çš„HTMLå®ä½“
    decoded = decoded
        .replace("&amp;lt;", "<")
        .replace("&amp;gt;", ">")
        .replace("&amp;quot;", "\"")
        .replace("&amp;apos;", "'")
        .replace("&amp;amp;", "&");
    
    // ç¬¬äºŒè½®ï¼šè§£ç æ ‡å‡†HTMLå®ä½“
    decoded = decoded
        .replace("&lt;", "<")
        .replace("&gt;", ">")
        .replace("&quot;", "\"")
        .replace("&apos;", "'")
        .replace("&nbsp;", " ")
        .replace("&copy;", "Â©")
        .replace("&reg;", "Â®")
        .replace("&trade;", "â„¢");
    
    // ç§»é™¤æ‰€æœ‰HTMLæ ‡ç­¾ (åŒ…æ‹¬<p>, <br>, <div>, <span>ç­‰)
    let tag_regex = Regex::new(r"<[^>]*>").unwrap();
    decoded = tag_regex.replace_all(&decoded, "").to_string();
    
    // æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
    let whitespace_regex = Regex::new(r"\s+").unwrap();
    decoded = whitespace_regex.replace_all(&decoded, " ").trim().to_string();
    
    // ç§»é™¤"è¯´æ˜ï¼š"ç­‰æè¿°æ€§å‰ç¼€ï¼Œæå–çº¯å‡€çš„ç¿»è¯‘å†…å®¹
    if decoded.contains("è¯´æ˜ï¼š") {
        if let Some(main_part) = decoded.split("è¯´æ˜ï¼š").next() {
            decoded = main_part.trim().to_string();
        }
    }
    
    // ç¡®ä¿æœ€ç»ˆç»“æœæ˜¯çº¯å‡€çš„ç¿»è¯‘æ–‡æœ¬
    decoded.trim().to_string()
}

fn escape_xml(text: &str) -> String {
    text.replace('&', "&amp;")
        .replace('<', "&lt;")
        .replace('>', "&gt;")
        .replace('"', "&quot;")
        .replace('\'', "&apos;")
}

fn get_data_directory() -> Result<std::path::PathBuf> {
    dirs::data_dir()
        .map(|dir| dir.join("WordPony"))
        .ok_or_else(|| anyhow!("æ— æ³•è·å–æ•°æ®ç›®å½•"))
}

async fn load_from_tauri_resource() -> Result<String> {
    // åœ¨æ‰“åŒ…åçš„åº”ç”¨ä¸­ï¼Œèµ„æºæ–‡ä»¶ä¼šè¢«åµŒå…¥åˆ°å¯æ‰§è¡Œæ–‡ä»¶ä¸­
    // è¿™é‡Œæˆ‘ä»¬å°è¯•ä»èµ„æºç›®å½•è¯»å–
    match std::env::current_exe() {
        Ok(exe_path) => {
            if let Some(exe_dir) = exe_path.parent() {
                // åœ¨Windows MSIå®‰è£…åï¼Œèµ„æºæ–‡ä»¶é€šå¸¸ä¸å¯æ‰§è¡Œæ–‡ä»¶åœ¨åŒä¸€ç›®å½•
                let resource_path = exe_dir.join("software_vocabulary.xml");
                
                if resource_path.exists() {
                    println!("ğŸ“ æ‰¾åˆ°èµ„æºæ–‡ä»¶: {:?}", resource_path);
                    return fs::read_to_string(resource_path)
                        .map_err(|e| anyhow!("è¯»å–èµ„æºæ–‡ä»¶å¤±è´¥: {}", e));
                }
                
                // ä¹Ÿå°è¯•åœ¨resourceså­ç›®å½•ä¸­æŸ¥æ‰¾
                let resources_path = exe_dir.join("resources").join("software_vocabulary.xml");
                if resources_path.exists() {
                    println!("ğŸ“ æ‰¾åˆ°resourcesç›®å½•ä¸­çš„æ–‡ä»¶: {:?}", resources_path);
                    return fs::read_to_string(resources_path)
                        .map_err(|e| anyhow!("è¯»å–resourcesæ–‡ä»¶å¤±è´¥: {}", e));
                }
            }
        }
        Err(e) => {
            println!("âš ï¸ æ— æ³•è·å–å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„: {}", e);
        }
    }
    
    Err(anyhow!("æœªæ‰¾åˆ°Taurièµ„æºæ–‡ä»¶"))
}

fn get_app_directory() -> Result<PathBuf> {
    // è·å–åº”ç”¨ç¨‹åºå®‰è£…ç›®å½•
    match std::env::current_exe() {
        Ok(exe_path) => {
            if let Some(app_dir) = exe_path.parent() {
                Ok(app_dir.to_path_buf())
            } else {
                Err(anyhow!("æ— æ³•è·å–åº”ç”¨ç¨‹åºç›®å½•"))
            }
        }
        Err(e) => Err(anyhow!("æ— æ³•è·å–å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„: {}", e))
    }
}

async fn create_default_vocabulary_file(path: &Path) -> Result<()> {
    // ç¡®ä¿ç›®å½•å­˜åœ¨
    if let Some(parent) = path.parent() {
        fs::create_dir_all(parent)?;
    }
    
    // å¤åˆ¶ç°æœ‰çš„ software_vocabulary.xml
    let current_dir = std::env::current_dir()?;
    let source_path = current_dir.join("software_vocabulary.xml");
    
    if source_path.exists() {
        fs::copy(&source_path, path)?;
    } else {
        // åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„ç©ºæ–‡ä»¶
        let default_content = r#"<?xml version="1.0" encoding="UTF-8"?>
<wordbook>
</wordbook>"#;
        fs::write(path, default_content)?;
    }
    
    Ok(())
} 